---
title: "DDMPE Open Restaurants Project"
author: Anna Benoit & Lina Cook
output: pdf_document
---

## Notes 
For lit review:
- https://www.restaurantdive.com/news/91-of-nyc-restaurants-say-permanent-outdoor-dining-is-very-important-to/618770/
- https://thecounter.org/dining-shed-banned-outdoor-restaurants-new-york-city-covid-19/

## Set up
```{r}
# load R libraries
library(janitor)
library(broom)
library(tidyverse)
library(tidyr)
library(kableExtra)
library(reticulate)
library(data.table)
library(XML)
library(RSocrata)
library(nominatimlite)
library(spatialrisk)

# load Python libraries
reticulate::py_install("pandas")
reticulate::py_install("usaddress")
reticulate::py_install("usaddress-scourgify", pip=TRUE)
```


## Helper objects and functions
```{r}
# helper objects
usaddress <- reticulate::import('usaddress')
scourgify <- reticulate::import('scourgify')


# helper functions

# normalize addresses

#  wrapper function to usaddress-scourgify that normalizes addresses and returns
#  a datatable of normalized addresses
normalize_address <- function(address_dat) {
  
  ## throw error if scourgify module is not imported
  if (! reticulate::py_module_available('scourgify')) {
    stop('The scourgify python module is not available in the default Python installation\n',
         'Install the usddress-scourgify module in R by calling:\n    reticulate::py_install("usaddress-scourgify",pip=TRUE)')
  }
  
  ## create object using purrr to specify how errors will be treated
  ##  in this case, errors will print "ERROR" across all address fields.
  poss_norm_addr <- purrr::possibly(.f = scourgify$normalize_address_record, otherwise = "ERROR")
  
  ## pass addresses to scourgify, which normalizes addresses
  ## according to US Post Office conventions.
  norm_addr <- furrr::future_map(address_dat, poss_norm_addr)
  
  ## bind list to dataframe for easier handling
  z_address_df <- as.data.frame(do.call(rbind, norm_addr))
  
  ## concatenate and edit output
  z_address_df <- z_address_df %>%
    ## trim postal codes
    mutate(postal_code = strtrim(z_address_df$postal_code, 5)) %>%
    ## concatenate
    unite(col = z_addr_cat, 1:5, sep = ", ", remove = FALSE, na.rm = TRUE) %>%
    ## move the concatenated, normalized address field to the first column
    dplyr::relocate(z_addr_cat, .before = address_line_1)

  ## remove NULL values
    ## from concatenated address field
    z_address_df$z_addr_cat <- gsub("NULL, ", "", z_address_df$z_addr_cat)
    ## from all other areas in dataframe
    z_address_df <- map_df(z_address_df, ~ gsub("NULL", "", .x))

  ## add raw address back on to results
  z_address_df <- cbind(address_dat, z_address_df) %>%
    rename(raw_addr = address_dat)
  
}

## Optional
# addTaskCallback(function(...) { system("say -v Victoria Bingo bongo!"); TRUE }, name = "announce when done")
```


## Import data
```{r}
# Sheds
#sheds <- fread("~/Downloads/Sidewalk_Sheds.csv")
#sheds <- fread("~/Downloads/Active_Sheds2.csv")

# Open restaurant application data
open_resto <- fread("~/Downloads/Open_Restaurant_Applications.csv")

# 2017
# dat_311_2017 <- fread("~/Downloads/dat_311_2017_exp.csv")

# sheds_geo
sheds_geo <- fread("~/Downloads/shed_geo.csv")

# intermediate exports
dat_311_2017 <- fread("~/Downloads/dat_311_2017_addr.csv") %>% 
  select(-shed_flag, -shed_biz)
sheds_clean <- fread("~/Downloads/sheds_clean.csv")


# # Parking violations
# parking <- read.socrata("https://data.cityofnewyork.us/resource/2bnn-yakx.csv")

# # 311 reports
#   ## 2017
#   dat_311_2017 <- read.socrata(
#     "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=created_date between '2017-01-01T00:00:00.000' and '2018-01-01T00:00:00.000'",
#     app_token = "K7vd3wbyWNClKnbSYV8rje01b",
#     email     = "amb10034@nyu.edu",
#     password  = "6@5t7d!!$Kh$FyL"
#   )
# 
#   ## 2018_1
#   start_time <- Sys.time() # 40m
#   dat_311_2018_1 <- read.socrata(
#     "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=created_date between '2018-01-01T00:00:00.001' and '2018-07-01T00:00:00.000'",
#     app_token = "K7vd3wbyWNClKnbSYV8rje01b",
#     email     = "amb10034@nyu.edu",
#     password  = "6@5t7d!!$Kh$FyL"
#   )
#   end_time <- Sys.time()
#   end_time - start_time
# 
#   ## 2018_2
#   start_time <- Sys.time() # 36m
#   dat_311_2018_2 <- read.socrata(
#     "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=created_date between '2018-07-01T00:00:00.001' and '2019-01-01T00:00:00.000'",
#     app_token = "K7vd3wbyWNClKnbSYV8rje01b",
#     email     = "amb10034@nyu.edu",
#     password  = "6@5t7d!!$Kh$FyL"
#   )
#   end_time <- Sys.time()
#   end_time - start_time
# 
#   ## 2019
#   start_time <- Sys.time() #2 hrs
#   dat_311_2019 <- read.socrata(
#     "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$where=created_date between '2019-01-01T00:00:00.001' and '2020-01-01T00:00:00.000'",
#     app_token = "K7vd3wbyWNClKnbSYV8rje01b",
#     email     = "amb10034@nyu.edu",
#     password  = "6@5t7d!!$Kh$FyL"
#   )
#   end_time <- Sys.time()
#   end_time - start_time
# 
# 
#   ## write out
#   write.csv(dat_311_2017, file = "~/Downloads/dat_311_2017.csv", row.names = FALSE)
#   write.csv(dat_311_2018_1, file = "~/Downloads/dat_311_2018_1.csv", row.names = FALSE)
#   write.csv(dat_311_2018_2, file = "~/Downloads/dat_311_2018_2.csv", row.names = FALSE)
#   write.csv(dat_311_2019, file = "~/Downloads/dat_311_2019.csv", row.names = FALSE)
```


## Filter data 
Complaint types of interest: Illegal Parking, Rodent, Noise - Street/Sidewalk, Noise - Commercial, Dirty Condition, Food Establishment (Descriptor: Rodents/Insects/Garbage)
```{r}
# 2017
dat_311_2017 <- dat_311_2017 %>% 
  filter(
         # complaint_type == 'Illegal Parking' | 
         complaint_type == 'Rodent' | 
         complaint_type == 'Noise - Street/Sidewalk' | 
         complaint_type == 'Noise - Commercial' | 
         complaint_type == 'Dirty Condition' | 
         complaint_type =='Food Establishment')
  
# 2018_1
dat_311_2018_1_exp <- dat_311_2018_1 %>% 
  filter(complaint_type == 'Illegal Parking' | 
         complaint_type == 'Rodent' | 
         complaint_type == 'Noise - Street/Sidewalk' | 
         complaint_type == 'Noise - Commercial' | 
         complaint_type == 'Dirty Condition' | 
         complaint_type =='Food Establishment')
  
# 2018_2
dat_311_2018_2_exp <- dat_311_2018_2 %>% 
  filter(complaint_type == 'Illegal Parking' | 
         complaint_type == 'Rodent' | 
         complaint_type == 'Noise - Street/Sidewalk' | 
         complaint_type == 'Noise - Commercial' | 
         complaint_type == 'Dirty Condition' | 
         complaint_type =='Food Establishment')
  
# 2019
dat_311_2019_exp <- dat_311_2019 %>% 
  filter(complaint_type == 'Illegal Parking' | 
         complaint_type == 'Rodent' | 
         complaint_type == 'Noise - Street/Sidewalk' | 
         complaint_type == 'Noise - Commercial' | 
         complaint_type == 'Dirty Condition' | 
         complaint_type =='Food Establishment')

  # ## write out
  # write.csv(dat_311_2017_exp, file = "~/Downloads/dat_311_2017_exp.csv", row.names = FALSE)
  # write.csv(dat_311_2018_1_exp, file = "~/Downloads/dat_311_2018_1_filt.csv", row.names = FALSE)
  # write.csv(dat_311_2018_2_exp, file = "~/Downloads/dat_311_2018_2_filt.csv", row.names = FALSE)
  # write.csv(dat_311_2019_exp, file = "~/Downloads/dat_311_2019_filt.csv", row.names = FALSE)
```


## Prepare for join
```{r}
# drop parking violations for now
dat_311_2017 <- dat_311_2017 %>% 
  filter(complaint_type != "Illegal Parking")

# Prep open resto data
open_resto <- open_resto %>% 
  rename(lat = Latitude, 
         lon = Longitude)
  
# Filter and cat 311 data
dat_311_2017 <- dat_311_2017 %>% 
  filter(address_type == "ADDRESS") %>% 
  ## clean up weird long spaces on some obs
  mutate(incident_address = gsub("    ", " ", incident_address)) %>%
  unite(addr_join, c("incident_address", "incident_zip"), sep = ", New York, NY ", remove = FALSE)
  
# Filter and cat shed data
sheds <- sheds %>% 
  unite(addr_join, c("House #", "Street Name",), sep = " ", remove = FALSE) %>% 
  unite(addr_join, c("addr_join", "Zip Code",), sep = ", New York, NY ", remove = FALSE)

# Filter and cat open resto data
open_resto <- open_resto %>% 
  mutate(`Building Number` = ifelse(`Building Number`=="undefined", "", `Building Number`)) %>% 
  unite(addr_join, c("Building Number", "Street"), sep = " ", remove = FALSE) %>% 
  unite(addr_join, c("addr_join", "Postcode"), sep = ", New York, NY ", remove = FALSE)

```


## Normalize address data
```{r}
# normalize data
dat_311_2017_norm <- normalize_address(dat_311_2017$addr_join)
sheds_norm <- normalize_address(sheds$addr_join)
open_resto_norm <- normalize_address(open_resto$addr_join)

# clean normalized data by dropping errors
dat_311_2017_norm <- dat_311_2017_norm %>% 
  filter(address_line_1 != "ERROR") # 242,980 obs remaining

sheds_norm <- sheds_norm %>% 
  filter(address_line_1 != "ERROR") # 171,272 obs remaining

open_resto_norm <- open_resto_norm %>% 
  filter(address_line_1 != "ERROR") # 171,272 obs remaining
```


## Join on address (exact match)
```{r}
# attach cleaned address field 
dat_311_2017 <- left_join(dat_311_2017, dat_311_2017_norm, by = c("addr_join" = "raw_addr"))
sheds <- left_join(sheds, sheds_norm, by = c("addr_join" = "raw_addr"))
open_resto <- left_join(open_resto, open_resto_norm, by = c("addr_join" = "raw_addr"))

# drop duplicates 
dat_311_2017 <- unique(dat_311_2017)
sheds <- unique(sheds)
open_resto <- unique(open_resto) #13,252 obs

# find match rate
table(open_resto$z_addr_cat %in% dat_311_2017$z_addr_cat)
table(open_resto$z_addr_cat %in% dat_311_2017$z_addr_cat)["TRUE"]/nrow(dat_311_2017) #28%

# add shed indicator (Open restaurants ordinance begins June 2020)
dat_311_2017 <- dat_311_2017 %>% 
   mutate(shed_flag = ifelse((z_addr_cat %in% open_resto$z_addr_cat), 1, 0)) # 19,100/133,616 (14%)


# drop shed status to only issued or re-issued, drop business type to corp or individual, or partnership
# sheds <- sheds %>% 
#   filter(`Permit Status` == "ISSUED" | 
#          `Permit Status` == "RE-ISSUED", 
#          `Owner's Business Type` == "CORPORATION" | 
#          `Owner's Business Type` == "INDIVIDUAL" | 
#           `Owner's Business Type` == "PARTNERSHIP")

# sheds <- sheds %>% 
#    filter(activity == "Construction or Maintenance")

# # change N/As in business name to NA
# sheds$`Owner's Business Name`[which(sheds$`Owner's Business Name` == "N/A")] <- NA

# # add business name
# dat_311_2017 <- dat_311_2017 %>% 
#   mutate(shed_biz = ifelse((shed_flag == 1), sheds$`Owner's Business Name`, NA))

# write out intermediate csv
# write.csv(dat_311_2017, file = "~/Downloads/dat_311_2017_addr.csv", row.names = FALSE)
# write.csv(sheds, file = "~/Downloads/sheds_clean.csv", row.names = FALSE)

# # find match rate
# table(sheds_norm$z_addr_cat %in% dat_311_2017_norm$z_addr_cat)
# table(sheds_norm$z_addr_cat %in% dat_311_2017_norm$z_addr_cat)["TRUE"]/nrow(dat_311_2017_norm) #23%

# # unique matches
# nrow(table(unique(dat_311_2017_norm$z_addr_cat)))

```


## Join on lat-long
```{r}
# # geocode shed data
# shed_geo <- geo_lite(address = sheds$z_addr_cat)

# write out
# write.csv(shed_geo, "~/Downloads/shed_geo.csv", row.names=F)

# join
  ## clean up for join
  sheds_geo <- unique(sheds_geo)
  sheds_geo <- sheds_geo %>% 
    filter(complete.cases(.))

  sheds_geo <- sheds_geo %>%
    rename(z_addr_cat=query)
  
  ## write out
  # write.csv(sheds_geo, "~/Downloads/sheds_geo_clean", row.names=F)
  
  ## join
  # sheds_geo_clean <- full_join(sheds_clean, sheds_geo, by="z_addr_cat")
  
  ## get unique cases
  # sheds_geo_clean <- unique(sheds_geo_clean)
  
  ## write out
  # write.csv(sheds_geo_clean, "~/Downloads/sheds_geo_clean", row.names=F)

```


## Radius tagging
```{r}
dat_311_2017 <- dat_311_2017 %>% 
  rename(lat = latitude,
         lon = longitude) # 252,010 obs

dat_311_2017 <- dat_311_2017 %>% 
  mutate(count = 1)

open_resto <- open_resto %>%
  mutate(count = 1)

dat_311_2017 <- concentration(dat_311_2017, open_resto, value = count, radius = 15)

dat_311_2017 <- dat_311_2017 %>% 
  mutate(shed_flag_rad = ifelse(concentration >= 1, 1, 0)) # 31,625/133,616 (23%)

# sheds_geo <- sheds_geo %>% 
#   mutate(count = 1)

#sheds_geo2 <- left_join(sheds_geo, sheds, by = "z_addr_cat")

# sheds_conc <- concentration(sheds_geo, dat_311_2017, value = count, radius = 25)

# dat_2017_conc <- concentration(dat_311_2017, sheds_geo, value = count, radius = 15)
# 
# dat_2017_conc <- dat_2017_conc %>% 
#   mutate(shed_flag_rad = ifelse(concentration >= 1, 1, 0))

```


## Summary statistics
- Summary tables of complaint types
```{r}
# 2017
  ## table sheds and complaint type
  table(dat_311_2017$shed_flag) # 23% of complaints in 2017 were from addresses that would later have sheds (preshed)
  table(dat_311_2017$complaint_type)

 ## comparing pre-shed and no shed
  complaint_type_2017 <- dat_311_2017 %>% 
    tabyl(complaint_type, shed_flag, 
           show_na = TRUE) %>% 
    adorn_totals("both") %>% 
    adorn_percentages("col") %>%
    adorn_pct_formatting(digits = 2) %>%
    adorn_ns()
  complaint_type_2017


# 2018
  ## table sheds and complaint type
  table(dat_311_2018$shed_flag) # 23% of complaints in 2017 were from addresses that would later have sheds (preshed)
  table(dat_311_2018$complaint_type)

 ## comparing pre-shed and no shed
  complaint_type_2018 <- dat_311_2018 %>% 
    tabyl(complaint_type, shed_flag, 
           show_na = TRUE) %>% 
    adorn_totals("both") %>% 
    adorn_percentages("col") %>%
    adorn_pct_formatting(digits = 2) %>%
    adorn_ns()
  complaint_type_2018

  
# 2019
  ## table sheds and complaint type
  table(dat_311_2019$shed_flag) # 23% of complaints in 2017 were from addresses that would later have sheds (preshed)
  table(dat_311_2019$complaint_type)

 ## comparing pre-shed and no shed
  complaint_type_2019 <- dat_311_2019 %>% 
    tabyl(complaint_type, shed_flag, 
           show_na = TRUE) %>% 
    adorn_totals("both") %>% 
    adorn_percentages("col") %>%
    adorn_pct_formatting(digits = 2) %>%
    adorn_ns()
  complaint_type_2019
```

- Year over year changes in each complaint type
```{r}

```


## Correlation matrix
```{r}

```



## NOTES
Tabulate complaint type and frequencies
```{r}
# table of complaint type frequencies in 2017
complaint_type_tab17 <- as.data.frame(table(dat_311_2017$complaint_type))

  ## write out
  write.csv(complaint_type_tab17, file = "~/Downloads/complaint_type_tab17.csv", row.names = FALSE)

# table of complaint type and zip in 2018_1
complaint_type_tab18_1 <- as.data.frame(table(dat_311_2018_1$complaint_type, dat_311_2018_1$incident_zip))

  ## write out
  write.csv(complaint_type_tab18_1, file = "~/Downloads/complaint_type_tab18_1.csv", row.names = FALSE)
  
# table of complaint type and zip in 2018_2
complaint_type_tab18_2 <- as.data.frame(table(dat_311_2018_2$complaint_type, dat_311_2018_2$incident_zip))

  ## write out
  write.csv(complaint_type_tab18_2, file = "~/Downloads/complaint_type_tab18_2.csv", row.names = FALSE)
  
# table of complaint type and zip in 2019
complaint_type_tab19 <- as.data.frame(table(dat_311_2019$complaint_type, dat_311_2019$incident_zip))

  ## write out
  write.csv(complaint_type_tab19, file = "~/Downloads/complaint_type_tab19.csv", row.names = FALSE)
  
  
  table(dat_311_2017$complaint_type[which(dat_311_2017$shed_flag==1)])
  table(dat_311_2017$complaint_type[which(dat_311_2017$shed_flag==0)])
```

