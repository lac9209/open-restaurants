---
title: "Lina's Analysis"
author: "Lina Cook"
date: "4/21/2022"
output: pdf_document
---

```{r, message = FALSE}
# load R libraries
library(janitor)
library(broom)
library(tidyverse)
library(tidyr)
library(kableExtra)
library(reticulate)
library(data.table)
library(XML)
library(RSocrata)
library(nominatimlite)
library(spatialrisk)
library(maps)
library(ggmap)
library(mapdata)

# load Python libraries
reticulate::py_install("pandas")
reticulate::py_install("usaddress")
reticulate::py_install("usaddress-scourgify", pip=TRUE)
```

```{r helper functions}
# address objects
usaddress <- reticulate::import('usaddress')
scourgify <- reticulate::import('scourgify')

# FCN: normalize addresses

# function to usaddress-scourgify that normalizes addresses and returns
# a datatable of normalized addresses
normalize_address <- function(address_dat) {
  
  ## throw error if scourgify module is not imported
  if (! reticulate::py_module_available('scourgify')) {
    stop('The scourgify python module is not available in the default Python installation\n',
         'Install the usddress-scourgify module in R by calling:\n    reticulate::py_install("usaddress-scourgify",pip=TRUE)')
  }
  
  ## create object using purrr to specify how errors will be treated
  ##  in this case, errors will print "ERROR" across all address fields.
  poss_norm_addr <- purrr::possibly(.f = scourgify$normalize_address_record, otherwise = "ERROR")
  
  ## pass addresses to scourgify, which normalizes addresses
  ## according to US Post Office conventions.
  norm_addr <- furrr::future_map(address_dat, poss_norm_addr)
  
  ## bind list to dataframe for easier handling
  z_address_df <- as.data.frame(do.call(rbind, norm_addr))
  
  ## concatenate and edit output
  z_address_df <- z_address_df %>%
    ## trim postal codes
    mutate(postal_code = strtrim(z_address_df$postal_code, 5)) %>%
    ## concatenate
    unite(col = z_addr_cat, 1:5, sep = ", ", remove = FALSE, na.rm = TRUE) %>%
    ## move the concatenated, normalized address field to the first column
    dplyr::relocate(z_addr_cat, .before = address_line_1)

  ## remove NULL values
    ## from concatenated address field
    z_address_df$z_addr_cat <- gsub("NULL, ", "", z_address_df$z_addr_cat)
    ## from all other areas in dataframe
    z_address_df <- map_df(z_address_df, ~ gsub("NULL", "", .x))

  ## add raw address back on to results
  z_address_df <- cbind(address_dat, z_address_df) %>%
    rename(raw_addr = address_dat)
  
}
```

```{r}
## Read in data
dat_311 <- read.csv("./data/dat_311_combined.csv")
## Make year variable, make created_date into date variable
dat_311 <- dat_311 %>% 
  mutate(year = as.numeric(substr(created_date, start = 1, stop = 4)),
         month = as.numeric(substr(created_date, start = 6, stop = 7)),
         created_date = as.Date(created_date, format = "%Y-%m-%d"),
         latlong = paste0(round(latitude, 4), ", ", 
                   round(longitude, 4)),
         after_2020 = case_when(
           year < 2020 ~ 0,
           year >= 2020 ~ 1))

## Create datasets of before or after 2020
dat_311_pre <- filter(dat_311, year < 2020)
dat_311_post <- filter(dat_311, year >= 2020)

## Read in Open Restaurant Applications
dat_or <- read.csv("./data/Open_Restaurant_Applications.csv")
```

```{r}
## Summary Table
# dat_311_pre %>% 
#   group_by(complaint_type) %>% 
#   summarise(
#     count = n()
#   )
# 
# dat_311_post %>% 
#   group_by(complaint_type) %>% 
#   summarise(
#     count = n()
#   )

table(dat_311$complaint_type, dat_311$after_2020)
```
```{r}
## Plot of overall number of 311 calls by day
count <- dat_311 %>% 
  count(created_date) %>% 
  mutate(year = as.numeric(substr(created_date, 1, 4)),
         after_2020 = case_when(
           year < 2020 ~ 0,
           year >= 2020 ~ 1
         ))

ggplot(data = count, aes(x = created_date, y = n)) +
  geom_line() +
  labs(x = "Date", y = "Count of 311 calls")
```
```{r}
## Plot of overall 311 calls per day by complaint type
count2 <- dat_311 %>% 
  group_by(complaint_type) %>% 
  count(created_date) %>% 
  mutate(year = as.numeric(substr(created_date, 1, 4)),
         after_2020 = case_when(
           year < 2020 ~ 0,
           year >= 2020 ~ 1
         ))

ggplot(data = count2, aes(x = created_date, y = n, color = complaint_type)) +
  geom_line(alpha = 0.5) +
  labs(x = "Date", y = "Count of 311 calls",
       color = "Complaint Type")
```

```{r}
## Plot of overall 311 calls per day by complaint type
ggplot(count2, aes(created_date, n)) + 
  geom_line() + 
  facet_wrap(~ complaint_type) +
  labs(x = "Date", y = "Count of 311 calls")
```

```{r}
## Make df of unique lat-long restaurant coordinates (rounded to 3 decimals for radius)
latlong_or <- tibble(
  latlong = paste0(round(dat_or$Latitude, 4), ", ", 
                   round(dat_or$Longitude, 4))) %>% 
  filter(latlong != "NA, NA") %>% 
  unique()

## Evaluate if each 311 lat-long is in the unique O.R. lat-long's
dat_311$shed <- dat_311$latlong %in% latlong_or$latlong
dat_311_pre$shed <- dat_311_pre$latlong %in% latlong_or$latlong
dat_311_post$shed <- dat_311_post$latlong %in% latlong_or$latlong
```

```{r}
table(dat_311_pre$shed)
table(dat_311_pre$shed)/nrow(dat_311_pre)*100
```

```{r}
table(dat_311_post$shed)
table(dat_311_post$shed)/nrow(dat_311_post)*100
```



```{r}
## Make map of NYC using lat-long: not great
# x = rows = latitude, from = 40.49912, to = 40.91346
# y = columns = longitude, from = -74.25453, to = -73.7006

states <- map_data("state")
NY <- subset(states, region %in% c("new york"))
NYC <- filter(NY, long <= -73.7006 & long >= -74.25453 & 
                lat <= 40.91346 & lat >= 40.49912)
counties <- map_data("county")
NY_county <- subset(counties, region == "new york")
remove(states, counties)


## Map plot, not looking the best if I'm honest
ggplot(data = NYC, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = NA) + 
  theme_void() + 
  geom_polygon(data = NY_county, #aes(fill = sqrt(residence_count)), 
               color = "black")

```

